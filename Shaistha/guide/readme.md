# Guide 

## Introduction:
Guide is a computer vision and deep learning based multi-purpose app aimed to fulfill 3 purposes - a travelers ready to go app, Guide to visually impaired people to help them experience life in a fun way! and last but not the least for cyber security community as a recon app.

This app mainly utilizes Google's ML toolkit Firebase to bring in some of the most intact features of the app including, object detection, text recognition and translation ( read optional), bar code scanning and reverse image search, copying text from image, landmark recognition, smart reply, etc.

Other features like Google Map, Image click and note making, info gathering based on the search ( Reverse search).

As Visually Impaired mode , it can work in basic mode with audio feature for easy use and button click and search.

## What is Firebase ML Kit?
Firebase ML Kit is a mobile SDK that makes it easier for mobile developers to include machine learning capabilities in their applications. It consists of the following pre-built APIs:

   ***Text Recognition***: To recognize and extract text from images.
   ***Face Detection***: To detect faces and facial landmarks along with contours.
   ***Object Detection and Tracking***: To detect, track and classify objects in camera and static images.
   ***Image Labelling***: Identify objects, locations, activities, animal species, and much more.
   ***Barcode scanning***: Scan and process barcodes.
   ***Landmark recognition***: Identifying popular landmarks in an image.
   ***Language ID***: To detect the language of the text.
   ***On-Device Translation***: Translating text from one language to another.
   ***Smart Reply***: Generating textual replies based on previous messages.

Apart from that one can use their custom image classification machine learning models ***(.tflite models)*** (https://www.tensorflow.org/lite/models ) using AutoML.

ML Kit is basically a wrapper over the complexities of including and using machine learning capabilities in your mobile app.

## Resources 
Firebase ML Kit Series by Hitanshu Dhawan (https://medium.com/androidiots/firebase-ml-kit-101-introduction-1f5e591b1daf)
Machine learning for mobile developers(https://developers.google.com/ml-kit/)
ML Kit for Firebase (https://firebase.google.com/docs/ml-kit)

## End Result

## Updates
- Add all the ML toolkit features
- Add Google MAP
- Add basic model for Visually impaired aided with audio.
- Add reverse search features for recon.
- Try tinkling with the model to add facial recognition especially for visuallt impaired people.

## Social Impact
Like i have mentioned above its made with 3 types of audience in mind

***Travelers***, ***Visually Impaired people*** and ***AI & Cyber security researchers***

Travelling can be difficult especially if you don't know how to read, write or speak the native language, this problem can be solved by text recognition and auto translation feature plus the google map and note making makes it easier to keep the trip from derailing! Plus its packed with other fun and helpful feature to make their live easier.

As for the visually impaired people a different basic mode will be made available with audio aid to guide them through their daily chores and also make it easy to navigate the app!

Lastly, security researchers can use it as a on the way recon app to search the web using the above given features almost instantly and make notes of the findings in a go too!
